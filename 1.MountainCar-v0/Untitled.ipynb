{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MountainCar-v0问题描述：\n",
    "### 介绍：\n",
    "A car is on a one-dimensional track, positioned between two \"mountains\". The goal is to drive up the mountain on the right; however, the car's engine is not strong enough to scale the mountain in a single pass. Therefore, the only way to succeed is to drive back and forth to build up momentum.\n",
    "- reward: -1 for each time step, until the goal position of 0.5 is reached. As with MountainCarContinuous v0, there is no penalty for climbing the left hill, which upon reached acts as a wall.\n",
    "\n",
    "### 动作空间：\n",
    "- 0: push left\n",
    "- 1: no push\n",
    "- 2: push right\n",
    "\n",
    "### 状态空间：\n",
    "- position: [-1.2,0.6]\n",
    "- velocity: [-0.07,0.07]\n",
    "- final state: position = 0.5 or 200 iterations\n",
    "- starting state: Random position from -0.6 to -0.4 with no velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.46205972,  0.        ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"MountainCar-v0\")\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 状态最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6 , 0.07], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 状态最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.2 , -0.07], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化Q表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_TABLE_LEN = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 20]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table_shape = [Q_TABLE_LEN] * len(env.observation_space.high)\n",
    "q_table_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table_shape = q_table_shape + [env.action_space.n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table = np.zeros(q_table_shape)\n",
    "q_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据state定位Q表索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Q_index_by_state (state):\n",
    "    temp = (env.observation_space.high - env.observation_space.low) / Q_TABLE_LEN\n",
    "    rst = (state - env.observation_space.low) // temp\n",
    "    return tuple(rst.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据epcilon-greedy策略获取动作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_q_action(q_index):\n",
    "    position_index = q_index[0]\n",
    "    velocity_index = q_index[1]\n",
    "    return np.argmax(q_table[position_index][velocity_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(state, epsilon):\n",
    "    q_index = get_Q_index_by_state(state)\n",
    "    if np.random.random() < epsilon:#随机取一个动作\n",
    "        return np.random.randint(0, env.action_space.n)\n",
    "    else:#取Q值最大的index\n",
    "        return get_max_q_action(q_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q value更新：\n",
    "$$\n",
    "Q(S_t, A_t) = Q(S_t, A_t) + \\alpha (R+\\gamma max_{a^{'}}Q(S_{t+1},a^{'})-Q(S_t,A_t))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_q_value(q_index):\n",
    "    position_index = q_index[0]\n",
    "    velocity_index = q_index[1]\n",
    "    return np.max(q_table[position_index][velocity_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_q_table(q_table, episode):\n",
    "    df = pd.DataFrame(q_table.reshape([400,3]))\n",
    "    df.columns = [\"0\", \"1\", \"2\"]\n",
    "    df.to_csv(\"./Q_Tabel_{}.csv\".format(episode), index=False, header=True, sep=\",\", encoding='utf-8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.02\n",
    "gamma = 0.95\n",
    "episodes = 50000\n",
    "record_times = 2000\n",
    "ep_rewards = []\n",
    "epsilon = 1\n",
    "epsilon_step = epsilon / (int(episodes/2) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-29e0c3615294>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-29e0c3615294>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ---\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(episodes):\n",
    "    ep_reward = 0\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = get_action(state, epsilon)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        ep_reward += reward\n",
    "        if not done:\n",
    "            td_target = reward + gamma * get_max_q_value(get_Q_index_by_state(next_state))\n",
    "            q_table[get_Q_index_by_state(state)][action] += alpha * (td_target - q_table[get_Q_index_by_state(state)][action])\n",
    "        elif next_state[0] >= 0.5:\n",
    "            q_table[get_Q_index_by_state(state)][action] = 0\n",
    "        state = next_state\n",
    "    print(\"[episode={},reward={}]\".format(episode, ep_reward))\n",
    "    if episode % record_times == 0:\n",
    "        save_q_table(q_table, episode)\n",
    "    epsilon -= epsilon_step\n",
    "    ep_rewards.append(ep_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存最终Q表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(q_table.reshape([400,3]))\n",
    "df.columns = [\"0\", \"1\", \"2\"]\n",
    "df.to_csv(\"./Q_Tabel_Final.csv\", index=False, header=True, sep=\",\", encoding='utf-8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存训练时每个episode的总reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ep_rewards)\n",
    "plt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结果测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table_data = pd.read_csv(\"./Q_Tabel_48000.csv\")\n",
    "q_table_tmp = q_table_data.values\n",
    "q_table_tmp = q_table_tmp.reshape([20,20,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "state = env.reset()\n",
    "actions = []\n",
    "while not done:\n",
    "    action = np.argmax(q_table_tmp[get_Q_index_by_state(state)])\n",
    "    actions.append(action)\n",
    "    next_state, _, done, _ = env.step(action)\n",
    "    state = next_state\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(q_table.reshape([400,3]))\n",
    "df.columns = [\"0\", \"1\", \"2\"]\n",
    "df.to_csv(\"./Q_Tabel_Final.csv\", index=False, header=True, sep=\",\", encoding='utf-8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.reshape([20,20,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
